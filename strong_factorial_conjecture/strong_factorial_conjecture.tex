\documentclass[a4paper]{article}
\title{Strong Factorial Conjecture}


% ---------------------------------------------------------------------
% P A C K A G E S
% ---------------------------------------------------------------------

% typography and formatting
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{exsheets}
\usepackage{environ}
\usepackage{graphicx}
\usepackage{cutwin}
\usepackage{pifont}

% mathematics
\usepackage{xfrac}  
\usepackage{amsthm} % for theorems, and definitions
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{mleftright} % for scaling mid bar in sets
% \usepackage{MnSymbol} % for \cupdot

% extra
\usepackage{xcolor}
\usepackage{tikz}

% ---------------------------------------------------------------------
% S E T T I N G
% ---------------------------------------------------------------------

%maybe delete later, for colorbox
\usepackage{tcolorbox}
\newtcolorbox{defbox}{colback=blue!5!white,colframe=blue!75!black}
\newtcolorbox{defboxlight}{colback=cyan!5!white,colframe=cyan!75!black}
\newtcolorbox{thmbox}{colback=orange!5!white,colframe=orange!75!black}
\newtcolorbox{rembox}{colback=purple!5!white,colframe=purple!75!black}
\newtcolorbox{exmbox}{colback=gray!5!white,colframe=gray!75!black}
\newtcolorbox{intbox}{colback=violet!5!white,colframe=violet!75!black}

% typography and formatting
\geometry{margin=3cm}

\SetupExSheets{
  counter-format = ch.qu,
  counter-within = chapter,
  question/print = true,
  solution/print = true,
}

% mathematics
\newcounter{global}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[]
\newtheorem{example}{Example}[definition]

\newtheorem{theorem}[definition]{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}

\newtheorem*{remark}{Remark}
\newtheorem*{intuition}{Intuition}

% extra
\definecolor{mathif}{HTML}{0000A0} % for conditions
\definecolor{maththen}{HTML}{CC5500} % for consequences
\definecolor{mathrem}{HTML}{8b008b} % for notes
\definecolor{mathobj}{HTML}{008800}

\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric, arrows}

% ---------------------------------------------------------------------
% C O M M A N D S
% ---------------------------------------------------------------------

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\rank}{\text{rank}}
\newcommand{\Vol}{\text{Vol}}

\newcommand{\set}[1]{\mleft\{\, #1 \,\mright\}}
\newcommand{\makeset}[2]{\mleft\{\, #1 \; \middle| \; #2 \,\mright\}}

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff{\mathop{}\!\mathrm{D}}

\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}

% ---------------------------------------------------------------------
% R E N D E R
% ---------------------------------------------------------------------

\newif\ifshowproof
\showprooftrue

\NewEnviron{Proof}{%
    \ifshowproof%
        \begin{proof}%
            \BODY
        \end{proof}%
    \fi%
}%

\begin{document}
% \maketitle
\tableofcontents

My notes on "The Strong Factorial Conjecture" by Eric Edo and Arno van den Essen.

See: https://arxiv.org/abs/1304.3956

\section{Factorial Conjecture}
%
For the first half of the coin, the Factorial Conjecture, presented here, let \(m \in \mathbb{N}_+\) be a positive integer and consider the set of all polynomials \(\mathbb{C}[X_1, X_2, \ldots, X_m]\) in \(m\) variables over \(\mathbb{C}\). In the interest of brevity, we will denote this set by \(\mathbb{C}^{[m]} := \mathbb{C}[X_1, X_2, \ldots, X_m]\).

Equipped with the usual addition and multiplication, \(\mathbb{C}^{[m]}\) forms a \(\mathbb{C}\)-algebra, and as such, it is generated by the following monomial basis
%
\begin{align*}
    \mathcal{B} = \makeset{X_1^{l_1} \cdots X_m^{l_m}}{l_k \in \mathbb{N}_0 \text{ for all } 1 \leq k \leq m} \text{.}
\end{align*}
%
Thus, any linear map is fully specified by its values on the elements of this basis. Such linear map is the factorial map.
%
\begin{definition}[Definition 2.1]
    A factorial map is a linear map linear map \(\mathcal{L}: \mathbb{C}^{[m]} \longrightarrow \mathbb{C}\) defined by
    \begin{align*}
        \mathcal{L}(X_1^{l_1} \cdots X_m^{l_m}) = l_1! \cdots l_m! \qquad \text{ for all } l_1, \ldots, l_m \in \mathbb{N}
    \end{align*}
\end{definition}
%
\begin{example}
    Consider \(f(X) = 3X - 5XY + 7Y^2 \in \mathbb{C}^{[2]}\). Applying the factorial map yields
    \begin{align*}
        \mathcal{L}(f(X)) &= 3\mathcal{L}(X) - 5 \mathcal{L}(XY) + 7 \mathcal{L}(Y^2) \\
        &= 3 \cdot 1 - 5 \cdot 1 + 7 \cdot 2 \\
        &= 12 \text{.}
    \end{align*}
\end{example}
%
\begin{example}
    If we limit our selves to a polynomial in one indeterminate, such as \(f(X) = \sum_{k = 0}^n a_k X^k \in \mathbb{C}[X]\) for a fixed \(n \in \mathbb{N}_0\) and \(a_k \in \mathbb{C}\) for all \(1 \leq k \leq n\), we have
    \begin{align*}
        \mathcal{L}(f(X)) = \sum_{k = 0}^n a_k \mathcal{L}(X^k) = \sum_{k=0}^n a_k k!
    \end{align*}
\end{example}
%
\begin{remark}[Remark 2.2]
    Let \(\sigma \in S_n\) be a permutation on the set \(\{X_1, \ldots, X_m\}\). We extend \(\sigma\) to an automorphism \(\tilde{\sigma}\) of the \(\mathbb{C}\)-algebra \(\mathbb{C}^{[m]}\) by setting
    \begin{align*}
        \tilde{\sigma} \left( X_1^{l_1} \cdots X_m^{l_m} \right) = \sigma(X_1)^{l_1} \cdots \sigma(X_m)^{l_m} \text{.}
    \end{align*}
    Then, \(\mathcal{L}(\tilde{\sigma}(f)) = \mathcal{L}(f)\) for any \(f \in \mathbb{C}^{[m]}\).
\end{remark}
\begin{proof}
    Let \(\sigma\) also denote the permutation on \(\{1, \ldots, m\}\) where \(\sigma(X_i) = X_{\sigma(i)}\). For any monomial \(X_1^{l_1} \cdots X_m^{l_m}\), we have
    \begin{align*}
        \mathcal{L}\left(\tilde{\sigma}\left(X_1^{l_1} \cdots X_m^{l_m}\right)\right) = 
        \mathcal{L} \left(X_{\sigma(1)}^{l_1} \cdots X_{\sigma(m)}^{l_m}\right) =
        l_1 ! \cdots l_m! 
    \end{align*}
    Thus, for any monomial basis element \(B \in \mathcal{B}\), \(\mathcal{L}(\tilde{\sigma}(B)) = \mathcal{L}(B)\). By linearity of both \(\tilde{\sigma}\) and \(\mathcal{L}\), it is
    \begin{align*}
        \mathcal{L}(\tilde{\sigma}(f)) = \mathcal{L}(f) \text{ for all } f \in \mathbb{C}^{[m]} \text{.}
    \end{align*}
\end{proof}
%
\begin{remark}[Remark 2.3]
    In general, the factorial map \(\mathcal{L}\) does not preserve multiplication. However, if two polynomials \(f\) and \(g\) do not share any indeterminates, i.e. there exsists a subset \(I \subset \{1, 2, \ldots, m\}\) such that
    \begin{align*}
        f(X) \in \mathbb{C}[X_k : k \in I] \; \text{ and } \; g(X) \in \mathbb{C}[X_k : k \not\in I] \text{,}
    \end{align*}
    then indeed \(\mathcal{L}(fg) = \mathcal{L}(f)\mathcal{L}(g)\).
\end{remark}
%
\begin{proof}
    % #WIP: Can be written better ...
    Let \(B_1 \in \mathcal{B}\) and \(B_2 \in \mathcal{B}\) two monomial basis elements of \(\mathbb{C}^{[m]}\) that do not share any indeterminates, i.e. there is a subset \(I \subset \{1, 2, \ldots, m\}\) such that \(B_1 \in \mathbb{C}[X_k : k \in I]\) and \(B_2 \in \mathbb{C}[X_k : k \not\in I]\).
    
    We first want to renumber the indeterminates conveniently. Let \(\sigma\) be a permutation on \(\set{X_1, \ldots, X_m}\) and \(\tilde{\sigma}\) an extension of \(\sigma\) to an automorphism on \(\mathbb{C}^{[m]}\) such that for an \(n \in \mathbb{N}\)
    \begin{align*}
        \tilde{\sigma}(B_1) \in \mathbb{C}[X_k : k \in \{1, \ldots, n\}] \; \text{ and } \; \tilde{\sigma}(B_2) \in \mathbb{C}[X_k : k \in \{n + 1, \ldots, m\}]
    \end{align*}
    
    Now, we have
    \begin{align*}
        \mathcal{L}(B_1)\mathcal{L}(B_2) &= \mathcal{L}(\tilde{\sigma}(B_1))\mathcal{L}(\tilde{\sigma}(B_1)) \\
        &= \mathcal{L}(X_1^{l_1} \cdots X_n^{l_n})\mathcal{L}(X_{n+1}^{l_{n+1}} \cdots X_m^{l_m}) \\
        &= l_1 ! \cdots l_n ! l_{n+1}! \cdots l_m \\
        &= \mathcal{L} (B_1 B_2) \text{.}
    \end{align*}
\end{proof}
%
\begin{example}
    To illustrate that the factorial map \(\mathcal{L}\) is not compatible with the multiplication, simply consider \(f(X) = X\) and \(g(X) = X\) in \(\mathbb{C}^{[1]}\). It is
    \begin{align*}
        \mathcal{L}(fg) = \mathcal{L}(X^2) = 2 \;\text{ while } \;\mathcal{L}(f) \mathcal{L}(g) = 1 \cdot 1 = 1 \text{.}
    \end{align*}
\end{example}
%
\begin{theorem}[Conjecture 2.4]
    If \(f \in \mathbb{C}^{[m]}\) is a polynomial with \(\mathcal{L}(f^k) = 0\) for all \(k \in \mathbb{N}_+\), then \(f = 0\).
\end{theorem}
%
\begin{example}
    % I'm not sure about this example
    Consider \(f(X) = a_0 + a_1X \in \mathbb{C}^{[1]}\). For \(f\) and \(f^2\), the factorial map gives
    \begin{align*}
        \mathcal{L}(f) &= a_0 + a_1 \\
        \mathcal{L}(f^2) &= \mathcal{L}(a_0^2 + 2a_0 a_1 X + a_1^2 X^2) = a_0^2 + 2 a_0 a_1 + 2 a_1^2 \text{.}
    \end{align*}    
    If \(f\) fulfills the condition for the aforementioned conjecture, we have \(a_0 + a_1 = 0\), so \(a_0 = -a_1\) in the first equation. Substituting in the second equation, yields \(a_0^2 - 2 a_0^2 + 2a_0^2 = a_0^2 = 0\), hence \(a_0 = a_1 = 0\).
\end{example}
%
We introduce the following notation. For a polynomial \(f \in \mathbb{C}^{[m]}\), \(\mathcal{N}(f)\) denotes the number of nonzero monomials in \(f\). For example, \(\mathcal{N}(1 + X + X^2) = 3\) and \(\mathcal{N}(XYZ) = 1\).
%
\begin{definition}
    Set the following subsets of \(\mathbb{C}^{[m]}\) to be
    \begin{align*}
        F^{[m]} &= \{0\} \cup \makeset{f \in \mathbb{C}^{[m]} \setminus \{0\}}{\text{there is some }k \in \mathbb{N}_+ \text{ such that }\mathcal{L}(f^k) \neq 0} \\
        F_n^{[m]} &= \{0\} \cup \makeset{f \in \mathbb{C}^{[m]} \setminus \{0\}}{\text{there is some }k \in \{n, \ldots, n + \mathcal{N}(f) - 1\} \text{ such that } \mathcal{L}(f^k) \neq 0} \\
        F_\cap^{[m]} &= \bigcap_{n \in \mathbb{N}_+} F_n^{[m]}
    \end{align*}
    We call \(F^{[m]}\) to be the factorial set and \(F^{[m]}_\cap\) to be the strong factorial set.
\end{definition}
%
\begin{remark}
    The polynomials of the factorial set \(F^{[m]}\) are precisely the polynomials that satisfy the factorial conjecture. Thus, the factorial conjecture can be reformulated to \(F^{[m]} = \mathbb{C}^{[m]}\).
\end{remark}
%
\begin{proof}
    The contraposition of the factorial conjecture states: If \(f \neq 0\), then there is some \(k \in \mathbb{N}_+\) such that \(\mathcal{L}(f^k) \neq 0\). Thus, if the factorial conjecture is true, then \(F^{[m]} = \mathbb{C}^{[m]}\).
\end{proof}
%
\begin{theorem}[Conjecture 2.8]
    All polynomials are in the strong factorial set, i.e. \(F_\cap^{[m]} = \mathbb{C}^{[m]}\).
\end{theorem}
%
\begin{remark}
    Let \(n \in \mathbb{N}_+\) be a positive integer.
    \begin{enumerate}
        \item Let \(f \in \mathbb{C}^{[m]}\) be a polynomial. \(f \in F_n^{[m]}\) if and only if for all \(k \in \{n, \ldots, n + \mathcal{N}(f) - 1\}\)
        \begin{align*}
            \mathcal{L}(f^k) = 0 \text{ implies } f = 0 \text{.}
        \end{align*}
        \item regular system of parameters
    \end{enumerate}
\end{remark}
%
\begin{remark}
    If \(\mathcal{N}(f) = 1\), i.e. \(f\) is a monomial, then \(f \in F_\cap^{[m]}\).
\end{remark}
\begin{proof}
    If \(\mathcal{N}(f) = 1\), then \(f = X_1^{l_1} \cdots X_m^{l_m}\) and \(f^k = X_1^{l_1 k} \cdots X_m^{l_m k}\). Thus, the only case where \(\mathcal{L}(f^k) = 0\) for any \(k \in \mathbb{N}_+\) is when \(f = 0\). Hence \(f\) lies in \(F_n^{[m]}\) for all \(n \in \mathbb{N}_+\) and we have \(f \in F_\cap^{[m]}\).
\end{proof}
\begin{remark}
    If \(f \in \mathbb{R}^{[m]}_{\geq 0}\), i.e. all nonzero coefficients are real and positive, then \(f \in F_\cap^{[m]}\).
\end{remark}
\begin{proof}
    Should be straight forward.
\end{proof}
%
\begin{remark}[2.11]
    See proof in other paper.
\end{remark}
%
\begin{example}
    Consider \(f = X_1 - X_2 \in \mathbb{C}^{[2]}\). For all \(n \in \mathbb{N}_+\),
    \begin{align*}
        \mathcal{L}(f^n) = \mathcal{L} \left( \sum_{k = 0}^n \binom{n}{k} X_1^{n-k}(-X_2)^k \right) = \sum_{k=0}^n \binom{n}{k} (n-k)! k! (-1)^k = \sum_{k=0}^n \frac{n!}{k!} k! (-1)^k = n! \sum_{k=0}^n (-1)^k
    \end{align*}
    Hence \(\mathcal{L}(f^n) = n!\) if \(n\) is even and \(\mathcal{L}(f^n) = 0\) otherwise. Since \(n\) or \(n + 1\) is even, we have \(f \in F_n^{[2]}\). Thus \(f \in F_\cap^{[2]}\).
    % #WIP: this example shows that SFC(2) can not be true in positive characteristc ... im not quite sure why
\end{example}
\newpage
\section{Rigidity Conjecture}

TODO: \(\mathbb{C}_0[[X]]\) the set of formal power series with the constant coefficient being \(0\) forms a \(\mathbb{C}\)-algebra with composition being the composition.
%
\subsection{Reciprocal of a Power Series}
\begin{definition}[Cauchy Product]
    For two power series \(f(X) = \sum_{k \in \mathbb{N}_0} a_k X^k \in \mathbb{C}[[X]]\) and \(g(X) = \sum_{k \in \mathbb{N}_0} b_k X^k \in \mathbb{C}[[X]]\), we define their Cauchy product by
    \begin{align*}
        f(X) \times g(X) := \sum_{k \in \mathbb{N}_0} c_k X^k \; \text{ where } \; c_k := \sum_{i = 0}^{k}a_i b_{k - i} \text{.}
    \end{align*}
\end{definition}
%
\begin{remark}
    If one of the power series is also a polynomial, the formula above produces the same result as primitivly expanding would do.
\end{remark}
%
\begin{example}
    Take the alternating series \(f(X) = \sum_{k \in \mathbb{N}_0} (-1)^k X^k\) and the geometric series \(g(X) = \sum_{k \in \mathbb{N}_0} X^k\) and consider their Cauchy product \(f \times g\). The coefficients of the product is given by
    \begin{align*}
        c_k = \sum_{i=0}^k a_i b_{k-i} = \sum_{i=0}^k (-1)^{i} (1)^{k-i} = \sum_{i=0}^{k} (-1)^{i} = \begin{cases}
            1 \text{ if \(k\) is even} \\
            0 \text{ if \(k\) is odd}
        \end{cases}
    \end{align*}
    hence we have \(f(X) \times g(X) = \sum_{k \in \mathbb{N}_0} X^{2k} = 1 + X^2 + X^4 + \cdots\).

    Notice that both the alternating series \(f\) and the geometric series \(g\) only converge for values \(|X| < 1\) and thus, through the lense of analysis, their product only makes sense with that limitation. However, as algebraists we are not beholden to such bounds.

    If we declare \(|X| < 1\), then with the help of the analytical tools, we may evaluate both series as
    \begin{align*}
        f(X) = \frac{1}{1 + X} \; \text{ and } \; g(X) = \frac{1}{1 - X}
    \end{align*}
    therefore
    \begin{align*}
        f(X) \cdot g(X) = \frac{1}{1 + X} \cdot \frac{1}{1 - X} = \frac{1}{1 - X^2}
    \end{align*}
    which matches our expectation exactly as the last expression is the simplied form of \(\sum_{k \in \mathbb{N}_0} X^{2k} = f(X) \times g(X)\).
\end{example}
\vspace*{1cm}
It is well-known that the set of power series over a ring is again a ring. In particular, \(\mathbb{C}[[X]]\) with the usual coefficient-wise addition and the Cauchy product is a commutative ring with unity. It is, however, not a field because not all power series have a mulitplicative inverse. It turns out however, that strikingly many of the power series have a mulitplicative inverse.
%
\begin{proposition}
    A power series \(f(X) = \sum_{k \in \mathbb{N}_0} a_k X^k\) has a mulitplicative inverse if and only if its constant coefficient \(a_0\) is non-zero.

    The reciprocal of \(f\), denoted by \(\) if it exsists, \#blablabla
    \begin{align*}
        b_0 = \frac{1}{a_0} \; \text{ and for \(k \geq 1\) it is } \; b_k = -\frac{1}{a_0} \sum_{i = 1}^{k} a_i b_{k-i}
    \end{align*}
\end{proposition}
%
\begin{example}
    Consider \(f(X) = \sum_{k=0}^\infty (k+1) X^k\)

    It's insane that the inverse is \((X - 1)^2\)
\end{example}
%
\begin{remark}
    Point out that the multiplicative inverse of the power series is a simple polynomial and in turn, many (maybe all, there was something with Gauss about this in algebra) polynomial only have an inverse as a power series. 
\end{remark}
%
\subsection{Formal Differentiation}
% definition copied from Wikipedia
\begin{definition}[Formal Differentiation]
    Given a formal power series \(f(X) = \sum_{k \in \mathbb{N}_0} a_k X^k \in \mathbb{C}[[X]]\) its \textit{formal derivative}, denoted \(f'\), is defined by
    \begin{align*}
        f'(X) := \sum_{k \in \mathbb{N}_0} a_k \cdot k \cdot X^{k-1} \text{.}
    \end{align*}
\end{definition}
%
When talking about differentiation, how can one resist to use the exponential function as an example?
%
\begin{example}
    Consider the series representation of \(ce^x\) which is
    \begin{align*}
        f(X) = \sum_{k \in \mathbb{N}_0} \frac{1}{k!} X^k \text{.}
    \end{align*}
    Formal differentiation gives
    \begin{align*}
        f'(X) = \sum_{k \in \mathbb{N}_+} \frac{c}{k!} \cdot k \cdot X^{k-1} = \sum_{k \in \mathbb{N}_+} \frac{c}{(k - 1)!} \cdot X^{k-1} = \sum_{k \in \mathbb{N}_0} \frac{c}{k!} X^k = f(X)\text{.}
    \end{align*}
    which is expected from analysis. Indeed, it is not difficult to show that \(f = f'\) if and only if \(f(X) = ce^X\). This proof can be found in functology book.
\end{example}
%
\begin{remark}
    difference with analytic view of differentiation
\end{remark}
\begin{proposition}[Linearity of Formal Differentiation]
    Formal differentiation as an operator is linear, i.e. if we view \(\mathbb{C}[[X]]\) as a \(\mathbb{C}\)-vector space, then \((\ast)': \mathbb{C}[[X]] \longrightarrow \mathbb{C}[[X]]\) satisfies additivity and homogeneity.
\end{proposition}
As expected, the usual rules of differentiation such as the product rule and the chain rule may be transfered one-to-one from the analytical world to the one of algebra and formal power series. For this paper, only the chain rule is of interest. Before we formaly introduce the chain rule however, we require the notion of composition of power series.
%
\subsection{Composition of Formal Power Series}
\begin{proposition}[Chain Rule]
    If \(f \in \mathbb{C}[[X]]\) and \(g \in \mathbb{C}[[X]]\) are two formal power series, then the formal differentiation on their composition may be expressed as
    \begin{align*}
        (f \circ g)' = (f' \circ g) \cdot g'
    \end{align*}
\end{proposition}


When we consider compositions of formal power series, we always want the constant term to be \(0\).

The following example is taken from:

https://math.stackexchange.com/questions/1212053/defining-composition-of-two-formal-series-what-is-going-on

\begin{example}
    Let \(f = \sum_{k \in \mathbb{N}_0} a_k X^k\) and \(g = 1 + X\). Consider \(f \circ g\). We have
    \begin{align*}
        f \circ g &= \sum_{k \in \mathbb{N}_0} a_k (1 + X)^k \\
        &= a_0 + a_1 + a_1 X + a_2 + 2 a_2 X + a_2 X^2 + \cdots
    \end{align*}
    If \(f \circ g\) is again a formal power series, then we should be able to write \(f \circ g = \sum_{k \in \mathbb{N}_+} c_k X^k\) for some \(c_k \in \mathbb{C}\). However, we see that \(c_0\) is the sum of all \(a_k\) and we cannot evaluate that as algebraists. Thus composition of formal power series only makes sense if the constant coefficient is \(0\).
\end{example}

\begin{proposition}
    % right now, it's copy pasted from enumerative combinatorics
    A power series \(f(X) = \sum_{k \in \mathbb{N}_+} a_k X^k \in \mathbb{C}[[X]]\) has a compositional inverse \(f^{-1}(X)\) if and only if \(a_1 \neq 0\), in which case \(f^{-1}(X)\) is unique.
\end{proposition}

\begin{proof}
    % copied from enumerative combinatorics
    Assume \(g(X) = b_1 X + b_2 X^2 + \cdots\) satisfies \(f(g(X)) = X\). We then have
    \begin{align*}
        a_1(b_1 X + b_2 X^2 + \cdots) + a_2(b_1 X + b_2 X^2 + \cdots)^2 + a_3(b_1 X + b_2 X^2 + \cdots)^3 = X
    \end{align*}
    Equating coefficients on both sides yields the infinite system of equations
    \begin{align*}
        a_1 b_1 &= 1 \\
        a_1 b_2 + a_2 b_1^2 &= 0 \\
        a_1 b_3 + 2a_2 b_1 b_2 + a_3 b_1^3 &= 0 \\
        &\vdots
    \end{align*}
\end{proof}
Another proof:

https://www.math.uwaterloo.ca/~dgwagner/co430I.pdf
%
But there is no simple formula for the coefficients of the inverse (see enumerative combinatorics).
%
\begin{lemma}[Lagrange Inversion Formula]
    Let \(K\) be a field of charateristic
    \begin{align*}
        f^{-1}(X) &= \sum_{n \in \mathbb{N}_+} b_n X^n\\
        \text{where } b_n &= \frac{1}{n} \cdot [X^{n-1}] \left(\frac{X}{f(X)}\right)^n
    \end{align*}
\end{lemma}
%
\begin{proof}
    We will prove that the given formula for \(b_n\), i.e. the \(n\)-th coefficient of the compositional inverse, is merited. Thus begin by fixing an arbitary integer \(n \in \mathbb{N}_+\).

    % TODO: above
    % TODO: since we fixed n at the beginning, we don't need it later anymore
    % TODO: unsure about the index k and n

    By proposition \#XXX, \(f\) is guranteed to have a unique compositional inverse which we will denote by \(f^{-1}(X) = \sum_{k \in \mathbb{N}_+} b_k X^k\) with \(b_k \in \mathbb{C}\) for all \(k \in \mathbb{N}_+\). Applying the original \(f\) to both sides yields \(f(f^{-1} (X)) = X\) on the left side and on the right we have
    \begin{align*}
        f\left( \sum_{k \in \mathbb{N}_+} b_k X^k \right) = \sum_{k \in \mathbb{N}_+} b_k f(X)^k
    \end{align*}
    due to the linearity of \(f\) as a map, thus \(X = \sum_{k \in \mathbb{N}_+} b_k f(X)^k\). Now, formal differentiation with the chain rule \#sure? gives
    \begin{align*}
        1 = \sum_{k \in \mathbb{N}_+} k \cdot b_k \cdot f(X)^{k-1} \cdot f'(X) \text{.}
    \end{align*}
    Let \(n \in \mathbb{N}\) \#with0? be an integer. \#moremotivation Dividing the above equation with the \(n\)-th power of the reciprocal produces
    \begin{align*}
        f(X)^{-n} = \sum_{k \in \mathbb{N}_+} k \cdot b_k \cdot f(X)^{k-n-1} \cdot f'(X) \text{.}
    \end{align*}
    After 
\end{proof}
%
\newpage
\subsection{Rigidity Conjecture}
%
\begin{theorem}[Conjecture 2.13]
    Let \(a(X) \in \mathbb{C}[X]\) be a polynomial of degree less or equal to \(m + 1 \in \mathbb{N}_+\) such that \(a(X) \equiv X \mod{X^2}\). If \(m\) consecutive coefficient of the compositional inverse \(a^{-1}(X)\) vanish, i.e. \(b_{n+1} = b_{n+2} = \cdots = b_{n+m} = 0\) for some \(n \in \mathbb{N}_+\) then \(a(X) = X\).
\end{theorem}
%
\begin{remark}
    If we denote the polynomial \(a(X)\) by \(\sum_{k \in \mathbb{N}_0}a_k X^k\) for some \(a_k \in \mathbb{C}\) for all \(k \in \mathbb{N}_0\), then the condition \(a(X) \equiv X \mod{X^2}\) amounts to \(a_0 = 0\) and \(a_1 = 1\).
\end{remark}
%
\begin{theorem}[Conjecture 2.14]
    Let \(a(X) \in \mathbb{C}[X]\) be a polynomial of degree less or equal to \(m + 1 \in \mathbb{N}_+\) such that \(a(X) \equiv X \mod{X^2}\). If the coefficients of \(X^{n+1}, \ldots, X^{n+m}\) of the compositional inverse vanish, then \(a(X) = X\).
\end{theorem}
%
\begin{remark}
    \(R(m)\) if and only if \(R(m)_n\) for all \(n \in \mathbb{N}_+\).
\end{remark}
%
% copied from Edo & van den Essen
\begin{lemma}[Lemma 2.16]
    Let \(f \in \mathbb{C}[[X]]\) and \(g \in \mathbb{C}[[X]]\) be two formal series such that \(f(X) \equiv g(X) \mod{X^2}\), i.e. the constant and the coefficient of the first degree agree. If \(f(X) \equiv g(X) \mod{X^n}\) for some integer \(n \geq 2\) then \(f^{-1}(X) \equiv g^{-1}(X) \mod{X^n}\).
\end{lemma}
\begin{proof}
    % TODO:
\end{proof}
%
\begin{proposition}
    \begin{enumerate}
        \item The polynomial \(a(X)\) is invertible for the composition.
        \item For all \(i \in \set{1, \ldots, \text{deg}(a - 1)}\), the coefficient \(a_i\) is nilpotent element in \(A\).
              I just don't see this ...
    \end{enumerate}
\end{proposition}
%
The following lemma and proof are due to \#XXX.
%
\begin{example}[See 5.4.4]
    \(f(X) = X e^{-X} = X \sum_{k=0}^\infty \frac{(-1)^k}{k!} X^k\)
    \begin{align*}
        [X^n]f^{-1}(X) = \frac{1}{n} [X^{n-1}] e^{nX}
    \end{align*}
\end{example}


\begin{lemma}[Lemma 2.20 (Additive Inversion Formula)]
    Let \(\alpha_1, \ldots, \alpha_m \in \mathbb{C}\) be complex numbers. The formal inverse of \(a(X) = X(1 - (\alpha_1 X + \cdots + \alpha_m X^m))\) is given by the following formula
    \begin{align*}
        a^{-1}(X) & = X \mleft( 1 + \frac{1}{n + 1} \sum_{n \geq 1} u_n X^n \mright)
        \intertext{where}
        u_n       & = \frac{1}{n!} \sum_{j_1 + 2 j_2 + \cdots + m j_m = n} \frac{(n + j_1 + \cdots + j_m)!}{j_1 ! \cdots j_m!} \alpha_1^{j_1} \cdots \alpha_m^{j_m}
    \end{align*}
\end{lemma}

\begin{proposition}[Proposition 2.23]
    Let \(\alpha_1, \ldots, \alpha_m \in \mathbb{C}\) be complex numbers and let \((u_n)_{n \in \mathbb{N}_+}\) be a sequence defined by AIF in Lemma 2.20. For all \(n \in \mathbb{N}_+\), the Rigidity Conjecture \(R(m)_n\) is equivalent to the following implication: If \(u_n = \cdots = u_{n + m - 1} = 0\) then \(\alpha_1 = \cdots = \alpha_m = 0\).
\end{proposition}

\begin{proof}

\end{proof}

\begin{theorem}
    \begin{enumerate}
        \item The inclusion \(E^{[m]} \subset F_n^{[m]}\) implies \(R(m)_n\)
    \end{enumerate}
\end{theorem}

\begin{definition}
    \begin{align*}
        E^{[m]}   & = \makeset{X_1 \cdots X_m (\mu_1 X_1 + \cdots + \mu_m X_m)}{\mu_1, \ldots, \mu_m \in \mathbb{C}} \subset                                  \\
        F^{[m]}_n & = \makeset{f \in \mathbb{C}^{[m]} \setminus \{0\}}{\mathcal{L}(f^k) \neq 0 \text{ for some } n \leq k \leq \mathcal{N}(f) - 1} \cup \{0\}
    \end{align*}
\end{definition}

\end{document}